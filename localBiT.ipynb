{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "112a2944",
   "metadata": {},
   "source": [
    "# `localBiT.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170953f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import core.shapefile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from core.getNeighbors import getNeighborsAreaContiguity,extractCentroidsFromShapefile, kNearestNeighbors\n",
    "from core.spatstats import calculateBivariateT\n",
    "\n",
    "# Load shapefile data\n",
    "#sf = core.shapefile.Reader(\"input/Hex437.shp\") # Synthetic data\n",
    "#sf =core.shapefile.Reader(\"input/NPA_2014_Mecklenburg.shp\") # Case study with Mecklenburg County\n",
    "sf =core.shapefile.Reader(\"input/US_County_Lower48.shp\") # Case study with CDC health data\n",
    "shapes = sf.shapes()\n",
    "\n",
    "# Prepare AREAS input for Queen's and Rook's contiguity\n",
    "AREAS = [[shape.points] for shape in shapes]  # Ensure proper structure for AREAS\n",
    "\n",
    "# Calculate neighbors using Queen's and Rook's contiguity\n",
    "##Wqueen, Wrook = getNeighborsAreaContiguity(AREAS)\n",
    "##neighbors = Wqueen  # Use Queen's contiguity for further analysis\n",
    "\n",
    "# Use k nearest neighbors instead of contiguity\n",
    "shapefile_path = \"input/US_County_Lower48.shp\"\n",
    "centroids = extractCentroidsFromShapefile(shapefile_path)\n",
    "\n",
    "# Compute k-nearest neighbors (adjust k as needed)\n",
    "k = 10  # Number of nearest neighbors\n",
    "neighbors = kNearestNeighbors(centroids, k=k)\n",
    "\n",
    "\n",
    "# Load and extract raw data from CSV\n",
    "#data = pd.read_csv(\"input/Hex437noNorm.csv\") # Synthetic data\n",
    "#data = pd.read_csv(\"input/CLT_Data_Bac_Elem.csv\") # Case study with Mecklenburg County\n",
    "data = pd.read_csv(\"input/County_48_CDC.csv\") # Case study with CDC health data\n",
    "\n",
    "id = data.OID_  # Unique IDs for spatial units\n",
    "var1 = data.OBESITY_Ad  # Variable 1 values in synthetic data\n",
    "var2 = data.FOODINSE_2 # Variable 2 values in synthetic data\n",
    "#var1 = data.Z2_Value90_50  # Variable 1 values in synthetic data\n",
    "#var2 = data.Z_Value90_50  # Variable 2 values in synthetic data\n",
    "#Cluster = data.Cluster  # Cluster membership (targeted special zones in synthetic data)\n",
    "#Edge = data.Edge  # Edge of special zones, useful for edge effect considerations\n",
    "\n",
    "\n",
    "#var1 = data.Bac  # Variable 1 values in Mecklenburg data: % of adults with bachelor's degree or higher\n",
    "#var2 = data.Elem  # Variable 2 values in synthetic data: average test scores of elementary school students\n",
    "\n",
    "\n",
    "# Create a dictionary mapping IDs to variables\n",
    "dataDictionary = {int(b): [var1[a], var2[a]] for a, b in enumerate(id)}\n",
    "areaKeys = list(dataDictionary.keys())\n",
    "\n",
    "# Standardize variables\n",
    "var1_std = [(val - np.mean(var1)) / np.std(var1) for val in var1]\n",
    "var2_std = [(val - np.mean(var2)) / np.std(var2) for val in var2]\n",
    "dataDictionary_std = {int(b): [var1_std[a], var2_std[a]] for a, b in enumerate(id)}\n",
    "\n",
    "\n",
    "# Compute BiT for each spatial unit\n",
    "BTValues = {}\n",
    "result = []\n",
    "for x in areaKeys:\n",
    "    keyList = neighbors[x]\n",
    "    currentT = calculateBivariateT(x, keyList, dataDictionary_std)\n",
    "    result.append(currentT)\n",
    "    BTValues[x] = currentT\n",
    "\n",
    "# Monte Carlo permutation for significance test\n",
    "plist = []\n",
    "pvalue = []\n",
    "dataLength = len(shapes)\n",
    "\n",
    "for x in areaKeys:\n",
    "    Nlist = list(range(dataLength))\n",
    "    betterClusters = 0\n",
    "    number = len(neighbors[x])\n",
    "    Nlist.remove(x)\n",
    "    for _ in range(999):  # Perform 999 random permutations\n",
    "        permKey = np.random.choice(Nlist, number, replace=False)\n",
    "        randomT = calculateBivariateT(x, permKey, dataDictionary_std)\n",
    "        if BTValues[x] > randomT:\n",
    "            betterClusters += 1\n",
    "    p = (betterClusters + 1) / 1000.0 # The most important result. The highest/lowest ones correspond to negative/positive clusters of bivariate spatial association\n",
    "    plist.append(p)\n",
    "    pvalue.append(p if p < 0.5 else 1 - p) # Adjust negative cluster's p-value to small values\n",
    "\n",
    "# Identify patterns at different significance levels\n",
    "idx0001 = []\n",
    "idx001 = []\n",
    "idx005 = []\n",
    "for x in areaKeys:\n",
    "    if plist[x] <= 0.001:\n",
    "        idx0001.append('pos_cluster')\n",
    "    elif plist[x] >= 0.999:\n",
    "        idx0001.append('neg_cluster')\n",
    "    else:\n",
    "        idx0001.append('NS')\n",
    "\n",
    "    if plist[x] <= 0.01:\n",
    "        idx001.append('pos_cluster')\n",
    "    elif plist[x] >= 0.99:\n",
    "        idx001.append('neg_cluster')\n",
    "    else:\n",
    "        idx001.append('NS')\n",
    "\n",
    "    if plist[x] <= 0.05:\n",
    "        idx005.append('pos_cluster')\n",
    "    elif plist[x] >= 0.95:\n",
    "        idx005.append('neg_cluster')\n",
    "    else:\n",
    "        idx005.append('NS')\n",
    "\n",
    "# Save results to a DataFrame and export to CSV\n",
    "df = pd.DataFrame({\n",
    "    'OBJECTID': id + 1,  # Add 1 to IDs for compatibility\n",
    "    #'Cluster': Cluster,\n",
    "    #'Edge': Edge,\n",
    "    'var1': var1,  # Original Variable 1 values\n",
    "    'var2': var2,  # Original Variable 2 values\n",
    "    'BiT': result,  # Computed BiT statistic\n",
    "    'p_sim': plist,  # Pseudo p-values\n",
    "    'p_value': pvalue,  # Adjusted p-values\n",
    "    'pattern005': idx005,  # Patterns at 0.05 significance level\n",
    "    'pattern001': idx001,  # Patterns at 0.01 significance level\n",
    "    'pattern0001': idx0001  # Patterns at 0.001 significance level\n",
    "})\n",
    "\n",
    "df.to_csv(\"result/BiT_County_CDC_Obesity_FoodInsecurity_10NN.csv\", index=False)\n",
    "#df.to_csv(\"result/BiT_Hex437_XY_Quali.csv\", index=False)\n",
    "#df.to_csv(\"result/BiT_Hex437_Z2Z_Quali_10_50_90.csv\", index=False)\n",
    "#df.to_csv(\"result/BiT_Meck_Bac_ELem.csv\", index=False)\n",
    "print(\"Processing Complete.\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
