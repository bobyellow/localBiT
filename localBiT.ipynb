{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "112a2944",
      "metadata": {
        "id": "112a2944"
      },
      "source": [
        "# `localBiT.py`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys, os\n",
        "\n",
        "# Only run this in Colab (itâ€™ll silently skip on your local machine)\n",
        "if 'google.colab' in sys.modules:\n",
        "    # 1) Download & unzip your repo from GitHub\n",
        "    !wget -q https://github.com/bobyellow/localBiT/archive/refs/heads/main.zip -O localBiT.zip\n",
        "    !unzip -q localBiT.zip\n",
        "    # 2) Change into the directory that was just created\n",
        "    %cd localBiT-main\n",
        "# 3) Ensure Python finds your modules\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "# Debug printout\n",
        "print(\"PWD:\", os.getcwd())\n",
        "print(\"Contents:\", os.listdir('.'))\n",
        "print(\"Has core?:\", os.path.isdir('core'))\n"
      ],
      "metadata": {
        "id": "TEt_1TeQxVes",
        "outputId": "dbe571f9-3ea6-4d71-e5b2-84786ebb8096",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "TEt_1TeQxVes",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/localBiT-main\n",
            "PWD: /content/localBiT-main\n",
            "Contents: ['localLeeL.ipynb', 'localBiMoranI.py', 'localBiT.ipynb', 'Dockerfile', 'localMultiGearyC.ipynb', 'core', 'input', 'py2nb.py', 'result', 'LICENSE', 'localLeeL.py', 'localBiMoranI.ipynb', 'README.md', 'localBiT.py', 'localMultiGearyC.py']\n",
            "Has core?: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "170953f6",
      "metadata": {
        "id": "170953f6",
        "outputId": "bc2fb227-a136-49bb-82b0-fdb176c7d100",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ShapefileException",
          "evalue": "Unable to open input/US_County_Lower48.dbf or input/US_County_Lower48.shp.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mShapefileException\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-cb7bfb6a3334>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#sf = core.shapefile.Reader(\"input/Hex437.shp\") # Synthetic data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#sf =core.shapefile.Reader(\"input/NPA_2014_Mecklenburg.shp\") # Case study with Mecklenburg County\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msf\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshapefile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input/US_County_Lower48.shp\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Case study with CDC health data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/localBiT-main/core/shapefile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    797\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"shp\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/localBiT-main/core/shapefile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, shapefile)\u001b[0m\n\u001b[1;32m    881\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_dbf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapeName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshp\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdbf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 883\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mShapefileException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unable to open %s.dbf or %s.shp.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mshapeName\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapeName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    884\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    885\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__shpHeader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mShapefileException\u001b[0m: Unable to open input/US_County_Lower48.dbf or input/US_County_Lower48.shp."
          ]
        }
      ],
      "source": [
        "import core.shapefile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from core.getNeighbors import getNeighborsAreaContiguity,extractCentroidsFromShapefile, kNearestNeighbors\n",
        "from core.spatstats import calculateBivariateT\n",
        "\n",
        "# Load shapefile data\n",
        "#sf = core.shapefile.Reader(\"input/Hex437.shp\") # Synthetic data\n",
        "#sf =core.shapefile.Reader(\"input/NPA_2014_Mecklenburg.shp\") # Case study with Mecklenburg County\n",
        "sf =core.shapefile.Reader(\"input/US_County_Lower48.shp\") # Case study with CDC health data\n",
        "shapes = sf.shapes()\n",
        "\n",
        "# Prepare AREAS input for Queen's and Rook's contiguity\n",
        "AREAS = [[shape.points] for shape in shapes]  # Ensure proper structure for AREAS\n",
        "\n",
        "# Calculate neighbors using Queen's and Rook's contiguity\n",
        "##Wqueen, Wrook = getNeighborsAreaContiguity(AREAS)\n",
        "##neighbors = Wqueen  # Use Queen's contiguity for further analysis\n",
        "\n",
        "# Use k nearest neighbors instead of contiguity\n",
        "shapefile_path = \"input/US_County_Lower48.shp\"\n",
        "centroids = extractCentroidsFromShapefile(shapefile_path)\n",
        "\n",
        "# Compute k-nearest neighbors (adjust k as needed)\n",
        "k = 10  # Number of nearest neighbors\n",
        "neighbors = kNearestNeighbors(centroids, k=k)\n",
        "\n",
        "\n",
        "# Load and extract raw data from CSV\n",
        "#data = pd.read_csv(\"input/Hex437noNorm.csv\") # Synthetic data\n",
        "#data = pd.read_csv(\"input/CLT_Data_Bac_Elem.csv\") # Case study with Mecklenburg County\n",
        "data = pd.read_csv(\"input/County_48_CDC.csv\") # Case study with CDC health data\n",
        "\n",
        "id = data.OID_  # Unique IDs for spatial units\n",
        "var1 = data.OBESITY_Ad  # Variable 1 values in synthetic data\n",
        "var2 = data.FOODINSE_2 # Variable 2 values in synthetic data\n",
        "#var1 = data.Z2_Value90_50  # Variable 1 values in synthetic data\n",
        "#var2 = data.Z_Value90_50  # Variable 2 values in synthetic data\n",
        "#Cluster = data.Cluster  # Cluster membership (targeted special zones in synthetic data)\n",
        "#Edge = data.Edge  # Edge of special zones, useful for edge effect considerations\n",
        "\n",
        "\n",
        "#var1 = data.Bac  # Variable 1 values in Mecklenburg data: % of adults with bachelor's degree or higher\n",
        "#var2 = data.Elem  # Variable 2 values in synthetic data: average test scores of elementary school students\n",
        "\n",
        "\n",
        "# Create a dictionary mapping IDs to variables\n",
        "dataDictionary = {int(b): [var1[a], var2[a]] for a, b in enumerate(id)}\n",
        "areaKeys = list(dataDictionary.keys())\n",
        "\n",
        "# Standardize variables\n",
        "var1_std = [(val - np.mean(var1)) / np.std(var1) for val in var1]\n",
        "var2_std = [(val - np.mean(var2)) / np.std(var2) for val in var2]\n",
        "dataDictionary_std = {int(b): [var1_std[a], var2_std[a]] for a, b in enumerate(id)}\n",
        "\n",
        "\n",
        "# Compute BiT for each spatial unit\n",
        "BTValues = {}\n",
        "result = []\n",
        "for x in areaKeys:\n",
        "    keyList = neighbors[x]\n",
        "    currentT = calculateBivariateT(x, keyList, dataDictionary_std)\n",
        "    result.append(currentT)\n",
        "    BTValues[x] = currentT\n",
        "\n",
        "# Monte Carlo permutation for significance test\n",
        "plist = []\n",
        "pvalue = []\n",
        "dataLength = len(shapes)\n",
        "\n",
        "for x in areaKeys:\n",
        "    Nlist = list(range(dataLength))\n",
        "    betterClusters = 0\n",
        "    number = len(neighbors[x])\n",
        "    Nlist.remove(x)\n",
        "    for _ in range(999):  # Perform 999 random permutations\n",
        "        permKey = np.random.choice(Nlist, number, replace=False)\n",
        "        randomT = calculateBivariateT(x, permKey, dataDictionary_std)\n",
        "        if BTValues[x] > randomT:\n",
        "            betterClusters += 1\n",
        "    p = (betterClusters + 1) / 1000.0 # The most important result. The highest/lowest ones correspond to negative/positive clusters of bivariate spatial association\n",
        "    plist.append(p)\n",
        "    pvalue.append(p if p < 0.5 else 1 - p) # Adjust negative cluster's p-value to small values\n",
        "\n",
        "# Identify patterns at different significance levels\n",
        "idx0001 = []\n",
        "idx001 = []\n",
        "idx005 = []\n",
        "for x in areaKeys:\n",
        "    if plist[x] <= 0.001:\n",
        "        idx0001.append('pos_cluster')\n",
        "    elif plist[x] >= 0.999:\n",
        "        idx0001.append('neg_cluster')\n",
        "    else:\n",
        "        idx0001.append('NS')\n",
        "\n",
        "    if plist[x] <= 0.01:\n",
        "        idx001.append('pos_cluster')\n",
        "    elif plist[x] >= 0.99:\n",
        "        idx001.append('neg_cluster')\n",
        "    else:\n",
        "        idx001.append('NS')\n",
        "\n",
        "    if plist[x] <= 0.05:\n",
        "        idx005.append('pos_cluster')\n",
        "    elif plist[x] >= 0.95:\n",
        "        idx005.append('neg_cluster')\n",
        "    else:\n",
        "        idx005.append('NS')\n",
        "\n",
        "# Save results to a DataFrame and export to CSV\n",
        "df = pd.DataFrame({\n",
        "    'OBJECTID': id + 1,  # Add 1 to IDs for compatibility\n",
        "    #'Cluster': Cluster,\n",
        "    #'Edge': Edge,\n",
        "    'var1': var1,  # Original Variable 1 values\n",
        "    'var2': var2,  # Original Variable 2 values\n",
        "    'BiT': result,  # Computed BiT statistic\n",
        "    'p_sim': plist,  # Pseudo p-values\n",
        "    'p_value': pvalue,  # Adjusted p-values\n",
        "    'pattern005': idx005,  # Patterns at 0.05 significance level\n",
        "    'pattern001': idx001,  # Patterns at 0.01 significance level\n",
        "    'pattern0001': idx0001  # Patterns at 0.001 significance level\n",
        "})\n",
        "\n",
        "df.to_csv(\"result/BiT_County_CDC_Obesity_FoodInsecurity_10NN.csv\", index=False)\n",
        "#df.to_csv(\"result/BiT_Hex437_XY_Quali.csv\", index=False)\n",
        "#df.to_csv(\"result/BiT_Hex437_Z2Z_Quali_10_50_90.csv\", index=False)\n",
        "#df.to_csv(\"result/BiT_Meck_Bac_ELem.csv\", index=False)\n",
        "print(\"Processing Complete.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}